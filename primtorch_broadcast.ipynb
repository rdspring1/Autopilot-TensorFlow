{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdspring1/Autopilot-TensorFlow/blob/master/primtorch_broadcast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PrimTorch and broadcasting\n",
        "Broadcasting allows for example elementwise binary operations on arrays of different sizes, such as adding a vector to each column of a matrix.\n",
        "PyTorch Eager supports implicit broadcasting and expansion of tensors for multi-tensor operations mimicking NumPy's behavior.\n",
        "\n",
        "PyTorch's docs: https://pytorch.org/docs/stable/notes/broadcasting.html\n",
        "\n",
        "NumPy's docs: https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
        "\n",
        "For PrimTorch we would like to avoid the situation when accelerating backends need to reimplement broadcasting rules themselves.\n",
        "\n",
        "Initially, `broadcast_in_dim` was added to PrimTorch as the general broadcast+expand operation following JAX's specification: https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.broadcast_in_dim.html\n",
        "\n",
        "One problem with JAX is that its first backend, XLA, supports only static shapes and it was a necessary requirement from XLA to have concrete output shape of an expanded tensor:"
      ],
      "metadata": {
        "id": "bhnoxrMS4TtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's print JAX graph with baked-in output shapes\n",
        "import jax\n",
        "from jax import make_jaxpr\n",
        "import jax.numpy as jnp\n",
        "a = jnp.ones((4, 1))\n",
        "b = jnp.ones((3,))\n",
        "print(make_jaxpr(lambda a, b: a + b)(a, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3SkP9u26lwJ",
        "outputId": "0ac7289a-609f-4b47-d1b2-715fdb13b46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ lambda ; a:f32[4,1] b:f32[3]. let\n",
            "    c:f32[1,3] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 3)] b\n",
            "    d:f32[4,3] = add a c\n",
            "  in (d,) }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we inherit the same problem with baked into the graph concrete output shape:"
      ],
      "metadata": {
        "id": "DgL7AAs07ME7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "from torch.fx.experimental.proxy_tensor import make_fx\n",
        "import torch._refs\n",
        "a = torch.ones((4, 1))\n",
        "b = torch.ones((3,))\n",
        "print(make_fx(lambda a, b: torch._refs.add(a, b))(a, b).graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTK3dL5n7LIW",
        "outputId": "55a30eed-6baa-4a3f-ae8a-730c3fe14db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "graph():\n",
            "    %a_1 : [#users=1] = placeholder[target=a_1]\n",
            "    %b_1 : [#users=1] = placeholder[target=b_1]\n",
            "    %broadcast_in_dim : [#users=1] = call_function[target=torch.ops.prims.broadcast_in_dim](args = (%a_1, [4, 3], [0, 1]), kwargs = {})\n",
            "    %broadcast_in_dim_1 : [#users=1] = call_function[target=torch.ops.prims.broadcast_in_dim](args = (%b_1, [4, 3], [1]), kwargs = {})\n",
            "    %add : [#users=1] = call_function[target=torch.ops.prims.add](args = (%broadcast_in_dim, %broadcast_in_dim_1), kwargs = {})\n",
            "    return add\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we try to add a (3, 3) matrix and a (3,) vector broadcasting involves expanding the shape (torch.unsqueeze) and then expanding the broadcasted dimensions (torch.expand) to a larger size.\n",
        "\n",
        "Vector's shape transformations:\n",
        "(3,) -> unsqueeze -> (1, 3) -> expand -> (3, 3)"
      ],
      "metadata": {
        "id": "-7RsrTIu8FUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(4, 1, device='cuda')\n",
        "b = torch.randn(3, device='cuda')"
      ],
      "metadata": {
        "id": "nh7LmUxFGvql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcast and expand is implicit in PyTorch Eager\n",
        "a + b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFPhYQLIGytg",
        "outputId": "d355ce07-5c24-4930-ee72-7d9405999f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8126,  0.9479, -0.5042],\n",
              "        [-0.8294,  0.9311, -0.5210],\n",
              "        [-1.9368, -0.1763, -1.6283],\n",
              "        [ 0.3101,  2.0706,  0.6186]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PrimTorch doesn't allow non-matching dims (implicit broadcasting)\n",
        "try:\n",
        "    torch._prims.add(a, b)\n",
        "except RuntimeError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QqDMKMEGzG_",
        "outputId": "1a0187bc-5500-4f8f-b937-f659cc80cb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape torch.Size([3]) is not the expected shape torch.Size([4, 1])!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PrimTorch also doesn't allow implicit expand\n",
        "try:\n",
        "    torch._prims.add(a, b.unsqueeze(0))\n",
        "except RuntimeError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8-4iuwp6Ts-",
        "outputId": "7545f881-7a7a-4be0-a6b3-5a612f14ad51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape torch.Size([1, 3]) is not the expected shape torch.Size([4, 1])!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nvFuser supports implicit expand (or \"stretch\" in NumPy's broadcasting page). We would like to modify PrimTorch's broadcasting primitive to have something that allows implicit expand of tensors since it enables support of dynamic shapes.\n",
        "\n",
        "![image.png](https://numpy.org/doc/stable/_images/broadcasting_4.png)\n",
        "\n",
        "Here's an example showing that implicit expand is well supported in nvFuser:"
      ],
      "metadata": {
        "id": "Dr8mDJh_-kyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C._nvfuser import Fusion, FusionDefinition\n",
        "\n",
        "fusion1 = Fusion()\n",
        "\n",
        "with FusionDefinition(fusion1) as fd :\n",
        "    t0 = fd.define_tensor(sizes=a.shape, strides=a.stride())\n",
        "    t1 = fd.define_tensor(sizes=b.unsqueeze(0).shape, strides=b.unsqueeze(0).stride())\n",
        "\n",
        "    fd.add_input(t0)\n",
        "    fd.add_input(t1)\n",
        "\n",
        "    t2 = fd.Ops.add(t0, t1)\n",
        "\n",
        "    fd.add_output(t2)\n",
        "\n",
        "# This doesn't print to the cell output\n",
        "# Check Runtime > View Runtime Logs\n",
        "fusion1.print_ir()\n",
        "\n",
        "# Execute Fusion\n",
        "print(fusion1.execute([a, b.unsqueeze(0)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQCjr8-n_VBW",
        "outputId": "b673734d-5402-4945-e997-bc41fbfd7fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[-0.8126,  0.9479, -0.5042],\n",
            "        [-0.8294,  0.9311, -0.5210],\n",
            "        [-1.9368, -0.1763, -1.6283],\n",
            "        [ 0.3101,  2.0706,  0.6186]], device='cuda:0')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's do one small modification to allow implicit expand for PrimTorch:"
      ],
      "metadata": {
        "id": "OFMy54NGaKcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_same_shape(a, b, allow_one_size=True) -> bool:\n",
        "    \"\"\"\n",
        "    Compares two shapes a and b, returning True if they are the same\n",
        "    (their ranks and corresponding lengths match) and False otherwise.\n",
        "    \"\"\"\n",
        "    if allow_one_size:\n",
        "        return all((x == y or x == 1 or y == 1 for x, y in zip(a, b)))\n",
        "    return tuple(a) == tuple(b)"
      ],
      "metadata": {
        "id": "wSoQqOpcJvJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Monkey-patching\n",
        "torch._prims.utils.is_same_shape = is_same_shape"
      ],
      "metadata": {
        "id": "IZM3YPb-8r7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now implicit expand is allowed\n",
        "torch._prims.add(a, b.unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBVDBDz39Zw3",
        "outputId": "5a285c72-d7df-4692-ca75-9cb396eef354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8126,  0.9479, -0.5042],\n",
              "        [-0.8294,  0.9311, -0.5210],\n",
              "        [-1.9368, -0.1763, -1.6283],\n",
              "        [ 0.3101,  2.0706,  0.6186]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\`broadcast_in_dim` can be split into special unsqueeze and normal expand operations. Let's define primitives for that. We call this special unsqueeze \"broadcast\". Given a list of bools that indicate whether the resulting tensor's dimension should be broadcasted or not. Effectively it inserts new size 1 dimensions at the specified positions."
      ],
      "metadata": {
        "id": "0BWpnZzSaUBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prim_impl = torch._prims.prim_impl\n",
        "torch._prims.prim.define(\"expand(Tensor input, int[] shape) -> Tensor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3AXK2HjILvHY",
        "outputId": "8a738ee5-4040-431c-b74b-5b02473ee9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'expand'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def broadcast(a, broadcast_dimensions):\n",
        "    \"\"\"Broadcasts the tensor to the given dimensions.\n",
        "       `broadcast_dimensions` is a sequence of bools indicating whether given dimension of the result is a broadcasted dimension.\n",
        "    \"\"\"\n",
        "    # We must have same number of False entries as a.ndim\n",
        "    assert a.ndim == len([x for x in broadcast_dimensions if not x])\n",
        "    for idx, is_broadcast_dim in enumerate(broadcast_dimensions):\n",
        "        if is_broadcast_dim:\n",
        "            a = a.unsqueeze(idx)\n",
        "    return a\n",
        "\n",
        "torch._prims.prim.define(\"broadcast(Tensor input, bool[] broadcast_dimensions) -> Tensor\")\n",
        "torch._prims.prim_impl.impl(\"broadcast\", broadcast)"
      ],
      "metadata": {
        "id": "XMi3RIscTgKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch._prims.prim_impl.impl(\"expand\", lambda inp, shape: inp.expand(shape))"
      ],
      "metadata": {
        "id": "FHyeNFf5PZmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define a new `torch._refs._maybe_broadcast` function that can be lowered into primitives that are directly mappable to nvFuser's broadcast."
      ],
      "metadata": {
        "id": "AYpyRHava-Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "\n",
        "# This a new variant of \"broadcast_in_dim\".\n",
        "# We don't necessarily need this. In the end all we'd like to see is explicit call to \"prims.broadcast\"\n",
        "# in the graph\n",
        "def refs_broadcast_in_dim(a, broadcast_dimensions, ndim, shape=None):\n",
        "    \"\"\"\n",
        "    Similar to jax.lax.broadcast_in_dim but now the expand part is optional.\n",
        "    We only unsqueeze to required `ndim` using `broadcast_dimensions`\n",
        "    \"\"\"\n",
        "    if shape is not None:\n",
        "        assert ndim == len(shape)\n",
        "\n",
        "    is_broadcast_dims = [True] * ndim\n",
        "    for broadcast_dimension in broadcast_dimensions:\n",
        "        is_broadcast_dims[broadcast_dimension] = False\n",
        "\n",
        "    a = torch.ops.prims.broadcast(a, is_broadcast_dims)\n",
        "\n",
        "    if shape is not None:\n",
        "        a = torch.ops.prims.expand(a, shape)\n",
        "    return a\n",
        "\n",
        "def _maybe_broadcast(*args, preserve_cpu_scalar_tensors=True):\n",
        "    # Copied from torch._refs._maybe_broadcast\n",
        "    common_shape = torch._refs._broadcast_shapes(\n",
        "        *map(lambda t: t.shape if isinstance(t, torch._prims.utils.TensorLike) else None, args)\n",
        "    )\n",
        "\n",
        "    def __maybe_broadcast(x, shape):\n",
        "        if x is None:\n",
        "            return None\n",
        "        elif isinstance(x, torch._prims.utils.Number):\n",
        "            return x\n",
        "        elif isinstance(x, torch._prims.utils.TensorLike):\n",
        "            if preserve_cpu_scalar_tensors and torch._prims.utils.is_cpu_scalar_tensor(x):\n",
        "                return x\n",
        "\n",
        "            if tuple(x.shape) != common_shape:\n",
        "                common_rank = len(common_shape) + 1\n",
        "                start = common_rank - (len(x.shape) + 1)\n",
        "                dims = tuple(range(start, len(x.shape) + start))\n",
        "                # NOTE: This line was changed in this function\n",
        "                return refs_broadcast_in_dim(x, dims, len(common_shape))\n",
        "        else:\n",
        "            raise RuntimeError(\n",
        "                \"Unexpected type when broadcasting: \" + str(type(x)) + \"!\"\n",
        "            )\n",
        "\n",
        "    return tuple(__maybe_broadcast(x, common_shape) for x in args)"
      ],
      "metadata": {
        "id": "9cNWB58JPucy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_maybe_broadcast(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6gNHWxuQSsE",
        "outputId": "e3d83ab0-dc48-4701-bce9-035b1dc7f054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.1531],\n",
              "         [-0.1699],\n",
              "         [-1.2773],\n",
              "         [ 0.9696]], device='cuda:0'),\n",
              " tensor([[-0.6595,  1.1010, -0.3510]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monkey-patching\n",
        "torch._refs._maybe_broadcast = _maybe_broadcast"
      ],
      "metadata": {
        "id": "I2J0ejmiQV16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's run again the same example from the top of this notebook and see the resulting graph. We don't save concrete shape of the inputs to the add call anymore."
      ],
      "metadata": {
        "id": "jcu1nBsbXxNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "from torch.fx.experimental.proxy_tensor import make_fx\n",
        "import torch._refs\n",
        "a = torch.ones((4, 1))\n",
        "b = torch.ones((3,))\n",
        "add_fx = make_fx(lambda a, b: torch._refs.add(a, b))(a, b)\n",
        "print(add_fx.graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-xWcF5NSfcu",
        "outputId": "12de0370-7fe1-4f14-d51c-558cc2e47b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "graph():\n",
            "    %a_1 : [#users=2] = placeholder[target=a_1]\n",
            "    %b_1 : [#users=1] = placeholder[target=b_1]\n",
            "    %broadcast : [#users=0] = call_function[target=torch.ops.prims.broadcast](args = (%a_1, [False, False]), kwargs = {})\n",
            "    %broadcast_1 : [#users=1] = call_function[target=torch.ops.prims.broadcast](args = (%b_1, [True, False]), kwargs = {})\n",
            "    %add : [#users=1] = call_function[target=torch.ops.prims.add](args = (%a_1, %broadcast_1), kwargs = {})\n",
            "    return add\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: mruberry\n",
        "# What would the grad transform of an add primitive that allowed for implicit \n",
        "# expansion be?\n",
        "# I think it would have to call something like sum_to_size (reproduced below)\n",
        "import torch._prims as prims\n",
        "import torch._prims.utils as utils\n",
        "\n",
        "def sum_to_size(\n",
        "    a: torch.Tensor,\n",
        "    *shape,\n",
        ") -> torch.Tensor:\n",
        "    shape = utils.extract_shape_from_varargs(shape, validate=False)\n",
        "    utils.check(\n",
        "        utils.is_expandable_to(shape, a.shape),\n",
        "        lambda: f'sum_to_size: size \"{shape}\" is not expandable to size \"{a.shape}\"',\n",
        "    )\n",
        "    # In ATen scalar tensors are sent through sum and the result is returned as\n",
        "    # type promoted\n",
        "    if utils.is_same_shape(shape, a.shape) and len(shape) > 0:\n",
        "        return prims.view_of(a)\n",
        "    leading_dims = a.ndim - len(shape)\n",
        "    reduce_dims = tuple(range(leading_dims)) + tuple(\n",
        "        i\n",
        "        for i in range(leading_dims, len(shape))\n",
        "        if shape[i - leading_dims] == 1 and a.shape[i] != 1\n",
        "    )\n",
        "    return torch.sum(a, dim=reduce_dims, keepdim=True, dtype=None)\n",
        "\n",
        "# I think sum_to_size will then encode the shape in the way we're hoping to avoid\n",
        "# Alternatives might be to make sum_to_size itself a primitive, or define a \n",
        "# new \"unary_elementwise_backward\" primitive\n",
        "\n",
        "# With symbolic shapes, however, I think expands can be not to a specific\n",
        "# value but to a symbol representing the shape of the other tensor"
      ],
      "metadata": {
        "id": "Uo4jmp-qm4gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install functorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yis3Eun2E64",
        "outputId": "2bf587d6-2f86-4f83-b840-ce755311eb45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting functorch\n",
            "  Downloading functorch-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (20.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<1.13,>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from functorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.13,>=1.12.1->functorch) (4.1.1)\n",
            "Installing collected packages: functorch\n",
            "Successfully installed functorch-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following won't work in this notebook because it doesn't have functorch\n",
        "# UPD: fixed by !pip install functorch above\n",
        "# This example is to illustrate the point about the distinct backwards\n",
        "\n",
        "import functorch\n",
        "import torch\n",
        "import torch.fx as fx\n",
        "\n",
        "from functorch.compile import aot_function#, make_boxed_func\n",
        "\n",
        "def foo(a, b):\n",
        "    return a + b\n",
        "\n",
        "def print_graph(name):\n",
        "    def f(fx_g: fx.GraphModule, inps):\n",
        "        print(name)\n",
        "        print(fx_g.code)\n",
        "        return fx_g\n",
        "    return f\n",
        "\n",
        "# Pass on the compiler_fn to the aot_function API\n",
        "aot_print_fn = aot_function(foo, fw_compiler=print_graph(\"forward\"), bw_compiler=print_graph(\"backward\"))\n",
        "\n",
        "a = torch.randn(2, 1, requires_grad=True)\n",
        "b = torch.randn(2, 2, requires_grad=True)\n",
        "ref = aot_print_fn(a, b)\n",
        "loss = ref.sum()\n",
        "loss.backward()\n",
        "\n",
        "# when a has shape (2, 2)\n",
        "# def forward(self, primals_1, primals_2):\n",
        "#     add = torch.ops.aten.add.Tensor(primals_1, primals_2);  primals_1 = primals_2 = None\n",
        "#     return [add]\n",
        "\n",
        "# def backward(self, tangents_1):\n",
        "#     return [tangents_1, tangents_1]\n",
        "\n",
        "\n",
        "# when a has shape (2, 1)\n",
        "# def forward(self, primals_1, primals_2):\n",
        "#     add = torch.ops.aten.add.Tensor(primals_1, primals_2);  primals_1 = primals_2 = None\n",
        "#     return [add]\n",
        "\n",
        "# def backward(self, tangents_1):\n",
        "#     sum_1 = torch.ops.aten.sum.dim_IntList(tangents_1, [1], True)\n",
        "#     return [sum_1, tangents_1]\n",
        "\n",
        "# Alternative for graph pass:\n",
        "# def backward(self, tangents_1, primals_1, primals_2):\n",
        "#     if is_implicitly_expanded(primals_1):\n",
        "#         sum_1 = torch.ops.aten.sum.dim_IntList(tangents_1, [1], True)\n",
        "#     if is_implicitly_expanded(primals_2):\n",
        "#         sum_2 = ...\n",
        "#     return [sum_1, sum_2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NImaFtGo8hsc",
        "outputId": "61427d14-3f2f-4660-bf30-ae91d5a29875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n",
            "\n",
            "\n",
            "\n",
            "def forward(self, primals_1, primals_2):\n",
            "    add = torch.ops.aten.add(primals_1, primals_2);  primals_1 = primals_2 = None\n",
            "    return [add]\n",
            "    \n",
            "backward\n",
            "\n",
            "\n",
            "\n",
            "def forward(self, tangents_1):\n",
            "    sum_1 = torch.ops.aten.sum(tangents_1, [1], True)\n",
            "    return [sum_1, tangents_1]\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When operations implicitly expand their forward is the same when implicit expansion occurs but their backwards is still distinct and suffers from explicit shapes. To address this issue we also have to redesign the backward and/or adopt symbolic shapes."
      ],
      "metadata": {
        "id": "pnObwgfWBCHz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3HnbAFb_A2gs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}